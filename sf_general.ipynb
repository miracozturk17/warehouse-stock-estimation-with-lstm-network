{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "from keras.models import Sequential, load_model # type: ignore\n",
    "from keras.layers import LSTM, Dense # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler # type: ignore\n",
    "import pyodbc # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from kerastuner.tuners import RandomSearch # type: ignore\n",
    "from keras.callbacks import EarlyStopping # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    connection_string = \"Driver={SQL Server Native Client 11.0};Server=MIRACLE\\\\MIRACOZTURK;Database=StokTahmin;uid=X;pwd=Y\"\n",
    "    try:\n",
    "        connection = pyodbc.connect(connection_string)\n",
    "        query = 'SELECT Tarih, StokKodu, SUM(Miktar) AS Miktar FROM StokTahmin.dbo.depo_stok GROUP BY Tarih, StokKodu ORDER BY Tarih DESC'\n",
    "        df = pd.read_sql_query(query, connection)\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Veritabani hatasi:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"Sorgu calistirilirken bir hata olustu:\", e)\n",
    "    finally:\n",
    "        if 'connection' in locals() and connection:\n",
    "            connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df['Miktar_scaled'] = scaler.fit_transform(df[['Miktar']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 30 # 30/60/90 gun yaklasimi.\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tarih'] = pd.to_datetime(df['Tarih'])\n",
    "df.sort_values(['StokKodu', 'Tarih'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(look_back, len(df)-1):\n",
    "    features.append(df['Miktar_scaled'].values[i-look_back:i])\n",
    "    labels.append(df['Miktar_scaled'].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32), input_shape=(look_back, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd']), loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directories_exist(directory, project_name):\n",
    "    full_path = os.path.join('C:\\\\Temp', directory, project_name)\n",
    "    os.makedirs(full_path, exist_ok=True)  # exist_ok=True, dizin zaten varsa hata vermemesini saglar.\n",
    "\n",
    "ensure_directories_exist('model_tuning', 'stock_prediction')\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='C:\\\\Temp\\\\model_tuning',\n",
    "    project_name='stock_prediction'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"En iyi hiperparametreler: \\n\"\n",
    "      f\"Units: {best_hps.get('units')}\\n\"\n",
    "      f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_ids = []\n",
    "units = []\n",
    "optimizers = []\n",
    "val_losses = []\n",
    "\n",
    "for trial in tuner.oracle.trials.values():\n",
    "    trial_ids.append(trial.trial_id)\n",
    "    units.append(trial.hyperparameters.values['units'])\n",
    "    optimizers.append(trial.hyperparameters.values['optimizer'])\n",
    "    val_losses.append(trial.score)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'trial_id': trial_ids,\n",
    "    'units': units,\n",
    "    'optimizer': optimizers,\n",
    "    'val_loss': val_losses\n",
    "})\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=results_df, x='units', y='val_loss', hue='optimizer', style='optimizer', s=100)\n",
    "plt.title('Hiperparametrelerin Doğrulama Kaybina Göre Performansi')\n",
    "plt.xlabel('Units')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend(title='Optimizer')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.loc[results_df['val_loss'].idxmin()]\n",
    "best_units = best_row['units']\n",
    "best_optimizer = best_row['optimizer']\n",
    "print(f\"En iyi modelin parametreleri: \\n{best_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Egitim Kaybi')\n",
    "plt.plot(history.history['val_loss'], label='Dogrulama Kaybi')\n",
    "plt.title('Model Kaybi')\n",
    "plt.ylabel('Kayip')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "predictions = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Test seti uzerindeki MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "for stock_code in df['StokKodu'].unique():\n",
    "    data = df[df['StokKodu'] == stock_code]\n",
    "    if len(data) >= look_back:\n",
    "        last_sequence = data['Miktar_scaled'].values[-look_back:].reshape(1, look_back, 1)\n",
    "        print(\"Boyut kontrolu - Last sequence shape:\", last_sequence.shape)\n",
    "\n",
    "        try:\n",
    "            future_stock = best_model.predict(last_sequence)\n",
    "            future_stock = scaler.inverse_transform(future_stock)\n",
    "        except Exception as e:\n",
    "            print(f\"{stock_code} stok kodu icin tahminleme hatasi: {e}\")\n",
    "            continue\n",
    "\n",
    "        last_date = data['Tarih'].iloc[-1]\n",
    "        last_stock = data['Miktar'].iloc[-1]\n",
    "\n",
    "        if last_stock == 0:\n",
    "            results[stock_code] = \"Stok zaten tukenmis.\"\n",
    "        else:\n",
    "            rate_of_depletion = future_stock[0, 0] / last_stock\n",
    "            if np.isinf(rate_of_depletion):\n",
    "                results[stock_code] = \"Tahmin edilemiyor.\"\n",
    "            else:\n",
    "                days_to_deplete = int(np.ceil(rate_of_depletion))\n",
    "                depletion_date = last_date + pd.Timedelta(days=days_to_deplete)\n",
    "                results[stock_code] = depletion_date.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        results[stock_code] = \"Yeterli veri yok.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock_code, depletion_date in results.items():\n",
    "    print(f\"Stok Kodu {stock_code} icin stoklarin bitecegi tahmini tarih: {depletion_date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
